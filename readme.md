# Duality AI Offroad Semantic Segmentation - Hackathon Submission

## ğŸ“‹ Project Overview

This repository contains our complete submission for the Duality AI Offroad Autonomy Segmentation Challenge. We developed a semantic segmentation model using DINOv2 backbone with a ConvNeXt-style segmentation head, achieving test IoU of **0.232** through systematic iterative optimization.

## ğŸ† Final Results

- **Validation IoU**: 0.355
- **Test IoU**: 0.232
- **Best Val Dice Score**: 0.509
- **Pixel Accuracy**: 72.92%

## ğŸ“ Repository Structure

```
project/
â”œâ”€â”€ code/                           # All source code
â”‚   â”œâ”€â”€ train_segmentation.py      # Training script with optimizations
â”‚   â”œâ”€â”€ test_segmentation.py       # Testing/inference script
â”‚   â”œâ”€â”€ inference.py                # Standalone inference on single images
â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ report/
â”‚   â””â”€â”€ report.docx                 # Complete hackathon report (8 pages)
â””â”€â”€ results/                        # Training outputs and metrics
    â”œâ”€â”€ evaluation_metrics.txt      # Final training metrics
    â”œâ”€â”€ segmentation_head.pth       # Trained model weights
    â”œâ”€â”€ loss and pixel accuracy/    # Training curves
    â”œâ”€â”€ Overall result/             # Combined metrics visualization
    â”œâ”€â”€ train an vlidation IoU vs Epoch/
    â””â”€â”€ Train Dice and Validation Dice vs Epoch/
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (recommended)
- Anaconda or Miniconda

### Installation

1. **Create environment**:
```bash
conda create -n segmentation python=3.8
conda activate segmentation
```

2. **Install dependencies**:
```bash
cd code
pip install -r requirements.txt
```

### Dataset Setup

Download the dataset from the [Duality AI Hackathon page](https://falconcloud.dualityai.com/) and organize as:

```
Offroad_Segmentation_Training_Dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Color_Images/
â”‚   â””â”€â”€ Segmentation/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ Color_Images/
â”‚   â””â”€â”€ Segmentation/
â””â”€â”€ testImages/
    â””â”€â”€ Color_Images/
```

Place the dataset folder in the parent directory of this project.

## ğŸ¯ Usage

### Training

To train the model with our optimized configuration:

```bash
python train_segmentation.py
```

**Training Configuration:**
- Optimizer: AdamW (lr=5e-4, weight_decay=1e-4)
- Scheduler: CosineAnnealingLR (T_max=25)
- Epochs: 25
- Batch size: 4
- Backbone: DINOv2-small (frozen)
- Augmentation: Horizontal flip, ColorJitter(0.3)

**Outputs:**
- Model weights: `segmentation_head.pth`
- Training curves: `train_stats/` directory
- Metrics log: `evaluation_metrics.txt`

### Testing

To evaluate on test set:

```bash
python test_segmentation.py
```

**Outputs:**
- Per-class IoU scores
- Mean IoU
- Predicted segmentation masks (optional)

### Inference on Single Images

```bash
python inference.py --image path/to/image.png --model segmentation_head.pth
```

## ğŸ§ª Model Architecture

**Backbone**: DINOv2-small
- Pre-trained Vision Transformer
- 384-dimensional embeddings
- Frozen during training

**Segmentation Head**: ConvNeXt-inspired
- Stem: 7Ã—7 conv (384 â†’ 128 channels)
- Processing block: Depthwise 7Ã—7 conv + 1Ã—1 conv
- Classifier: 1Ã—1 conv to 10 classes
- Bilinear upsampling to original resolution

## ğŸ“Š Optimization Journey

Our systematic approach improved validation IoU from **0.294 â†’ 0.355**:

### Iteration 1: Extended Training
- Change: 10 â†’ 25 epochs
- Gain: +0.017 IoU

### Iteration 2: Optimizer Switch â­
- Change: SGD â†’ AdamW
- Gain: +0.043 IoU (largest improvement!)

### Iteration 3: LR Scheduling
- Change: Added CosineAnnealingLR
- Result: Smoother convergence, final val IoU 0.355

## ğŸ”¬ Augmentation Experiments

We tested aggressive augmentation to address the validation-test gap (0.355 â†’ 0.232):

| Strategy | Augmentation | Test IoU | Change |
|----------|-------------|----------|--------|
| **Baseline** | Standard | **0.232** | Baseline |
| Aggressive | ColorJitter(0.5), Blur, Grayscale, Rotation(20Â°) | 0.163 | -30% âŒ |
| Moderate | ColorJitter(0.3), Rotation(10Â°) | 0.176 | -24% âŒ |

**Key Finding**: Aggressive augmentation degraded performance by destroying domain-specific features (desert color palette). We submit the baseline model.

## ğŸ“ˆ Per-Class Performance

| Class | Training % | Test IoU |
|-------|-----------|----------|
| Sky | 36.85% | 0.9463 âœ… |
| Landscape | 16.65% | 0.5606 âœ… |
| Dry Grass | 11.96% | 0.1818 |
| Rocks | 6.17% | 0.1050 |
| Dry Bushes | 6.58% | 0.0951 |
| Trees | 3.35% | 0.0851 âš ï¸ |
| Logs | 5.17% | 0.0653 âš ï¸ |
| Ground Clutter | 6.23% | 0.0599 âš ï¸ |
| Lush Bushes | 5.30% | 0.0156 âŒ |

**Pattern**: Strong on large, color-consistent classes (Sky, Landscape). Struggles with small, texture-heavy objects (Trees, Bushes, Logs).

## ğŸ§  Key Learnings

1. **Optimizer matters**: AdamW gave +0.043 IoU over SGD for transformer backbones
2. **Domain shift is real**: 34% val-test gap despite both being desert environments
3. **Augmentation can harm**: Destroyed domain-specific features when too aggressive
4. **Systematic experimentation**: Understanding failures is as valuable as successes

## ğŸ“– Report

Complete documentation available in `report/report.docx`:
- Iterative optimization process
- Augmentation experiments
- Failure analysis
- Training curves and visualizations
- Lessons learned and future work

## ğŸ”§ Troubleshooting

**Out of memory during training**:
- Reduce batch size in `train_segmentation.py`
- Use smaller input resolution

**DINOv2 download issues**:
- Model downloads automatically from torch.hub
- Requires internet connection on first run
- Cached locally after first download

**Missing dataset error**:
- Verify dataset path in scripts
- Check folder structure matches expected layout

## ğŸ’¡ Future Improvements

1. **Domain-adaptive augmentation**: Preserve color palette, vary lighting
2. **Multi-scale features**: Better small object detection
3. **Larger backbone**: DINOv2-base or -large
4. **Class-specific strategies**: Different augmentation per class
5. **Progressive training**: Start minimal, gradually increase augmentation

## ğŸ™ Acknowledgments

- **Duality AI** for organizing the hackathon and providing synthetic data
- **Facebook Research** for DINOv2 backbone
- **Challenge dataset** generated using FalconCloud digital twin platform

## ğŸ“ Citation

If using this code, please cite:

```
Duality AI Offroad Autonomy Segmentation Challenge 2026
Model: DINOv2-small + ConvNeXt Segmentation Head
Final Test IoU: 0.232
```

## ğŸ“ Contact

For questions about this submission, please reach out via the Duality AI Discord channel.

---

**Competition**: Duality AI Offroad Autonomy Segmentation Challenge  
**Date**: February 2026  
**Final Submission**: Optimized Baseline Model (Test IoU: 0.232)
